# condensedMNIST

## Abstract
MNIST trainset can be reduced from 60000 to 20953 by using a Relative Neighborhood Graph(RNG). The classification results in DNNs are no different from the original data set and better than random sampling.

## Method
RNG is one of the neighbor graphs. It's represent adjacency between nodes as their edges. 

When creating a RNG for a dataset, take the following steps:
1. For a pair of examples, draw two hypersphere whose radius is the distance between the pairs.
2. If no other points exist in the overlapping region of the two hyperspheres, connect a edge.

After creation, we pick out the points connected by edges to one or more points belonging to different classes. Thereby, we get the representative subsetã€€for decision boundaries.

## Results
### DNN Classification(dnn.py)
The test accuracy for each dataset when training DNN with 4 fully connected layers and ReLU. 

The number of epochs is 50 but the number of iterations is kept the same.

| Mode          | Number of Samples |   Test Acc   |
|---------------|:-----------------:|:------------:|
| Full          |       60000       |     96.7     |
| Condensed     |       20953       |     97.8     |
| Random        |       20953       |     96.2     |

### k-Nearest-Neighbor Classification
coming soon...
